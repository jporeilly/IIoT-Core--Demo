## <font color='red'>Data Catalog 7.0 Preflight - Hardware & Utils</font>  

The following pre-requisites configure the Data Catalog 7.0.

Prerequisites for the DC 7.0 server:
* Docker
* Docker Compose
* Docker Registry + UI 

* k3s - Rancher
* PostgreSQL

<font color='teal'>This section is for reference only. These tasks have already been completed.</font>

---

<em>Install Docker / Docker Compose</em>

The following script prepares an Ubuntu 20.04 server for DC 7.0.  
Docker Registry is installed with a HTTP connection.

``run the script:``
```
cd /data/Workshop-DC/01--Pre-flight
sudo ./pre-flight_dc.sh
```

--- 

<em>Docker Registry</em>

Docker client always attempts to connect to registries by first using HTTPS. You must configure your Docker client so that it can connect to insecure registries. In your Docker client is not configured for insecure registries, you will see the following error when you attempt to pull or push images to Harbor:  

```Error response from daemon: Get https://myregistrydomain.com/v2/users/: dial tcp myregistrydomain.com:443 getsockopt: connection refused.```

Resolution: 
* Ensure the /etc/docker/daemon.json has the IP or FQDN. 
* Ensure all the containers have started. Check containers in Docker section of VSC.

```
{
"insecure-registries" : ["myregistrydomain.com:port", "0.0.0.0"]
}
```

* finally test that the Docker Regsitry is up and running

  > navigate to: http://localhost:8080

``login into the Registry:``
```
docker login localhost:5000
Username: admin
Password: admin   
```

---

<em>Install k3s - Rancher</em> 

K3s is an official CNCF sandbox project that delivers a lightweight yet powerful certified Kubernetes distribution designed for production workloads across resource-restrained, remote locations or on IoT devices.

``run the script:``
```
cd /data/Workshop-DC/01--Pre-flight
sudo ./install_k3s.sh
```
Note: k3s is installed with Traefik disabled. Not required for single node.

---

<em>Install PostgresSQL database</em>

PostgreSQL is used as the primary data store or data warehouse for many web, mobile, geospatial, and analytics applications. PostgreSQL can store structured and unstructured data in a single product.

``workshop directory:``
```
cd /data/Workshop-DC/01--Preflight
```

``create a data-source namespace:``
```
kubectl create namespace data-source
kubectl get namespace
```

``create a postgres secret:``
```
kubectl create -f postgres-configmap.yml -n data-source
``` 
Note: As you all know that Docker containers are ephemeral in nature. All the data which is generated by or in the container will be lost after termination of the container instance.

To save the data, we will be using Persistent volumes and persistent volume claim resource within Kubernetes to store the data on persistent storages.
Here, we are using local directory/path as Persistent storage resource (/mnt/data)

``define persistent storage:``
```
kubectl create -f postgres-storage.yml -n data-source
```
Note: PostgreSQL manifest for deployment of PostgreSQL container uses PostgreSQL latest image. It is using PostgreSQL configuration like username, password, database name from the configmap that we created earlier. It also mounts the volume created from the persistent volumes and claims to make PostgreSQL containerâ€™s data persists.

``check if the PVC is connected to the PV successfully:``
```
kubectl get pvc -n data-source
```
Note: The status of the PVC is Bound, and the PVC is ready to be used in the PostgreSQL deployment.

``deploy PostgresSQL:``
```
kubectl apply -f postgres-deployment.yml -n data-source
```

``configure the PostgreSQL service:``
```
kubectl create -f postgres-service.yml -n data-source
```
Note: To access the deployment or container, we need to expose PostgreSQL service. Kubernetes provides different type of services like ClusterIP, NodePort and LoadBalancer.

``list all resources on the system:``
```
kubectl get all -n data-source
```
Note: make a note of the port used to connect to PostgreSQL.

``log into the PostgreSQL instance:``
```
kubectl exec -it [postgres-xxxxx] -n data-source --  psql -h 10.0.0.1 -U admin --password -p [port] postgresdb
```
Password: password
``log in as root:``
```
kubectl exec -it [postgres-xxxxx] -n data-source --  container postgres --sh
```

to delete PostgresSQL resources:
```
kubectl delete service postgres -n data-source
kubectl delete deployment postgres -n data-source
kubectl delete configmap postgres-config -n data-source
kubectl delete persistentvolumeclaim postgres-pv-claim -n data-source
kubectl delete persistentvolume postgres-pv-volume -n data-source
```

---

<em>Install pgAdmin 4</em>

PGAdmin is a web-based GUI tool used to interact with the Postgres database sessions, both locally and remote servers as well. You can use PGAdmin to perform any sort of database administration required for a Postgres database.

``workshop directory:``
```
cd /data/Workshop-DC/01--Preflight
```

``create a pgadmin namespace:``
```
kubectl create namespace pgadmin
kubectl get namespace
```

``create a pgadmin secret:``
```
kubectl create -f pgadmin-secret.yml -n pgadmin
```
``define connection settings:``
```
kubectl create -f pgadmin-configmap.yml -n pgadmin
```
``deploy pgadmin service:``
```
kubectl create -f pgadmin-service.yml -n pgadmin
```
``configure the pgadmin statefulset:``
```
kubectl create -f pgadmin-statefulset.yml -n pgadmin
```

To retrieve the ClusterIPs:

``pgadmin ClusterIP:``
```
kubectl get svc -n pgadmin -o wide
```
``PostgreSQLdb ClusterIP:``
```
kubectl get svc -n data-source -o wide
```

  > browse to: http://<PGADMIN_CLUSTERIP>:8000

intial credentials:    
User: pgadmin@hv.com    
Password: SuperSecret

---

<em>Copy over Postgres driver to Data Catalog Agent</em>

``retrive DC Agent Pod name:``
```
kubectl get pods -n ldc
```

``retrieve init-Container name:``
```
kubectl get pod POD_NAME_HERE -n ldc -o jsonpath="{.spec['containers','initContainers'][*].name}"
```

```
cd /data/Workshop--DC/01--Pre-flight/resources
kubectl cp postgresql-42.3.4.jar ldc/ldc-agent-xxxxx:/opt/ldc/agent/ext --container=agent
```

---